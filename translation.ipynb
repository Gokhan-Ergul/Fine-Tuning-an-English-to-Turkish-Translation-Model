{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e43138f5-c577-48bd-8dd9-11a9230fdc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb1a88ef-32d7-49d3-8766-5ada03e40b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: ff4f1dda-7c84-42a1-b689-727ea8489f0e)')' thrown while requesting HEAD https://huggingface.co/datasets/kde4/resolve/main/README.md\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 153438\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\"kde4\",lang1= \"en\", lang2 = 'tr')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ed1e569-9292-4013-8305-5b1eaa2e0806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 138094\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 15344\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_ds = dataset['train'].train_test_split(seed=101,train_size=0.9)\n",
    "split_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aecb3e1-666d-4c3e-b0f7-dec0d3195c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'Starting month of the fiscal year', 'tr': 'Mali yılın başlangıç ayı'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_ds['train'][23]['translation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3cabf52-c368-44c2-8782-f54de213fc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "check_point = 'Helsinki-NLP/opus-mt-tc-big-en-tr'\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(check_point)\n",
    "tokenizer = AutoTokenizer.from_pretrained(check_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd995494-5ee8-4f0e-a570-4276518b37a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Öğrenmenin en iyi yolu yapmaktır.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_translate = \"The best way to learn is by doing\"\n",
    "inputs = tokenizer(text_to_translate, return_tensors = 'pt')\n",
    "translated_tokens = model.generate(**inputs)\n",
    "translated_text = tokenizer.decode(translated_tokens[0], skip_special_tokens=True)\n",
    "translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f9a50ed-265e-443e-82a4-86d7e80b8bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 138094\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'translation'],\n",
       "        num_rows: 15344\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b1e4c92-fcec-4d52-b92b-6836dac9c538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '103429',\n",
       " 'translation': {'en': 'Chat with %1', 'tr': '% 1 ile sohbet et'}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "468eaa57-ea59-4404-9b7b-840045ed56d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (890 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of the tokenized_en: 7.422683099917448 , standart_devision: 11.69622304809656, median:5.0\n",
      "duration:8.537915215999988\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import statistics\n",
    "start_time = time.perf_counter()\n",
    "length_list = []\n",
    "for i in split_ds['train']['translation']:\n",
    "    tokenized_example_en = tokenizer(i['en'])\n",
    "    length = len(tokenized_example_en['input_ids'])\n",
    "    length_list.append(length)\n",
    "\n",
    "print(f\"mean of the tokenized_en: {statistics.mean(length_list)} , standart_devision: {statistics.stdev(length_list)}, median:{statistics.median(length_list)}\")\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "duration = end_time - start_time\n",
    "print(f\"duration:{duration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f1d549-b692-47f6-a2a3-bcd910cedad6",
   "metadata": {},
   "source": [
    "## for your memory use this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ba6d1c6-0e2d-4e42-8501-abe63ea9d3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 7.422683099917448\n",
      "Standard Deviation: 11.696180699246419\n",
      "Median: 5.0\n",
      "duration:0.6049959889999741\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "start_time = time.perf_counter()\n",
    "def length_of_en_token(example):\n",
    "    en_batch = [en['en'] for en in example['translation']]\n",
    "    tokenized_en = tokenizer(en_batch)\n",
    "    return {'length': [len(i) for i in tokenized_en['input_ids']]}\n",
    "\n",
    "lengths_ds = split_ds.map(length_of_en_token, batched=True, num_proc=4)\n",
    "\n",
    "length_list_fast = lengths_ds['train']['length']\n",
    "\n",
    "print(f\"Mean: {np.mean(length_list_fast)}\")\n",
    "print(f\"Standard Deviation: {np.std(length_list_fast)}\")\n",
    "print(f\"Median: {np.median(length_list_fast)}\")\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "duration = end_time - start_time\n",
    "print(f\"duration:{duration}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4382ce8a-15e7-4b86-b348-e4be345bd484",
   "metadata": {},
   "source": [
    "# this shows us how much map important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "745aa1e6-d269-4128-9b4e-9f3377978030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_fun(example):\n",
    "    source_text = [ex['en'] for ex in example['translation']]\n",
    "    target_text = [ex['tr'] for ex in example['translation']]\n",
    "    inputs = tokenizer(source_text,max_length=128, padding='longest', truncation=True)\n",
    "    \n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(target_text,max_length=128, padding='longest', truncation=True)\n",
    "        \n",
    "    inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return inputs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51096254-18d9-4ed6-8d1b-e5665435f37b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 138094\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 15344\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk_ds = split_ds.map(\n",
    "     tokenizer_fun,\n",
    "    batched=True,\n",
    "    remove_columns=split_ds[\"train\"].column_names,\n",
    ")\n",
    "tk_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21e335b6-60e5-4449-8e10-4a9ce5013a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainer, Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0488377e-ba51-4f2d-b470-093876472c2a",
   "metadata": {},
   "source": [
    "we don't need to change paddings with -100 for input_ids manually because data_collator already handles it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e678f48e-5a03-47c7-9ae1-df65f775f45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e82d3067-892e-4939-bdcc-60ad46b290fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data_collator([tk_ds[\"train\"][i] for i in range(7,9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70d39fb6-2d50-48f5-9418-84faff9b27db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'attention_mask', 'labels', 'decoder_input_ids']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(batch.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199203da-6165-4a51-b71a-6bcd25d7fc9a",
   "metadata": {},
   "source": [
    "the model already knows the padding values it labeled with 57059"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3428d44-cc44-42bf-93e1-457b7c9775bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4698, 13254, 23479, 51664, 29453,    33, 29477, 32858, 43741, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059],\n",
       "        [  151, 53200,  6806, 31375, 43741, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44527702-baed-4f74-98cb-e2a72f87fe42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[57059,  4698, 13254, 23479, 51664, 29453,    33, 29477, 32858, 43741,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059],\n",
       "        [57059,   151, 53200,  6806, 31375, 43741, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059, 57059,\n",
       "         57059, 57059]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['decoder_input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6d5d6192-2910-4103-8fe1-679e7ca3057c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sacrebleu\n",
      "  Using cached sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Using cached portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: regex in /home/gokhan/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages (from sacrebleu) (2024.11.6)\n",
      "Collecting tabulate>=0.8.9 (from sacrebleu)\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/gokhan/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages (from sacrebleu) (1.26.4)\n",
      "Collecting colorama (from sacrebleu)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting lxml (from sacrebleu)\n",
      "  Downloading lxml-6.0.2-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
      "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading lxml-6.0.2-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: tabulate, portalocker, lxml, colorama, sacrebleu\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5/5\u001b[0m [sacrebleu]/5\u001b[0m [colorama]\n",
      "\u001b[1A\u001b[2KSuccessfully installed colorama-0.4.6 lxml-6.0.2 portalocker-3.2.0 sacrebleu-2.5.1 tabulate-0.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "58971b0c-2d09-4618-83ae-a0527e552b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "metric = evaluate.load('sacrebleu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8276826-3ee2-4bb8-a712-8f709b846e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 46.750469682990165,\n",
       " 'counts': [11, 6, 4, 3],\n",
       " 'totals': [12, 11, 10, 9],\n",
       " 'precisions': [91.66666666666667,\n",
       "  54.54545454545455,\n",
       "  40.0,\n",
       "  33.333333333333336],\n",
       " 'bp': 0.9200444146293233,\n",
       " 'sys_len': 12,\n",
       " 'ref_len': 13}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [\n",
    "    \"This plugin lets you translate web pages between several languages automatically.\"\n",
    "]\n",
    "references = [\n",
    "    [\n",
    "        \"This plugin allows you to automatically translate web pages between several languages.\"\n",
    "    ]\n",
    "]\n",
    "metric.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "381174ac-b919-45dd-afb3-31cc7b5f45ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57059"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23ad7a29-f5cf-4939-b5fd-48a6575e3278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    decoded_preds = [pred.strip() for pred in decoded_preds]\n",
    "\n",
    "    decoded_labels = [[label.strip()] for label in decoded_labels]\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    return {\"bleu\": result[\"score\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f7ea998-dbd8-4d97-b44e-0224fb7544d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basarili\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"hf_XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "print('basarili')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c50ddf9b-ec0b-48e2-a15b-333ae04d464d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kullanıcı Adı: gokhanErgul\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import whoami\n",
    "try:\n",
    "    user_info = whoami()\n",
    "    print(\"Kullanıcı Adı:\", user_info['name'])\n",
    "except Exception as e:\n",
    "    print(\" Giriş yapılamadı\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d1a4487-820a-4dda-b755-7a5a202042a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kullanılacak Gerçek Batch Boyutu: 8\n",
      "Gradyan Biriktirme Adımları: 8\n",
      "Modelin Hissedeceği Etkili Batch Boyutu: 64\n"
     ]
    }
   ],
   "source": [
    "#bu degisikliklerle 3 saat 33 dakikaya indi 12 saatten.\n",
    "\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"kde4-en-to-tr_with-Helsinki\",\n",
    "    \n",
    "    eval_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=2,\n",
    "    \n",
    "    per_device_train_batch_size=8,\n",
    "\n",
    "    gradient_accumulation_steps=8,\n",
    "    \n",
    "    # Değerlendirme batch boyutu (eğitimin 2 katı genellikle güvenlidir)\n",
    "    per_device_eval_batch_size=16,\n",
    "    \n",
    "    # fp16, hem VRAM kullanımını azaltır hem de RTX 30 serisi kartlarda \n",
    "    fp16=True,\n",
    "    \n",
    "    # Veri yüklemeyi hızlandırmak için (CPU çekirdek sayınıza göre artırılabilir)\n",
    "    dataloader_num_workers=8,\n",
    "    \n",
    "    # torch_compile=True, \n",
    "    \n",
    "    # Değerlendirme ve Hub\n",
    "    predict_with_generate=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "# Ayarları kontrol edelim\n",
    "effective_batch_size = args.per_device_train_batch_size * args.gradient_accumulation_steps\n",
    "print(f\"Kullanılacak Gerçek Batch Boyutu: {args.per_device_train_batch_size}\")\n",
    "print(f\"Gradyan Biriktirme Adımları: {args.gradient_accumulation_steps}\")\n",
    "print(f\"Modelin Hissedeceği Etkili Batch Boyutu: {effective_batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "be411bc2-757f-4cb2-9681-e44d96ab0544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_833/2180442542.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tk_ds[\"train\"],\n",
    "    eval_dataset=tk_ds[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d1c26698-35d4-4a4d-97a5-8f6e219d40b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/240 14:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgokhannergull\u001b[0m (\u001b[33mgokhannergull-student\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.1s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/gokhan/hugging_face/translate/wandb/run-20251011_143830-w9xte81y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gokhannergull-student/huggingface/runs/w9xte81y' target=\"_blank\">glad-totem-5</a></strong> to <a href='https://wandb.ai/gokhannergull-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gokhannergull-student/huggingface' target=\"_blank\">https://wandb.ai/gokhannergull-student/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gokhannergull-student/huggingface/runs/w9xte81y' target=\"_blank\">https://wandb.ai/gokhannergull-student/huggingface/runs/w9xte81y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 9.69012451171875,\n",
       " 'eval_model_preparation_time': 0.0029,\n",
       " 'eval_bleu': 13.689495555514489,\n",
       " 'eval_runtime': 925.0187,\n",
       " 'eval_samples_per_second': 16.588,\n",
       " 'eval_steps_per_second': 0.259}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8ad0960-c219-455f-a6cd-f7ba41cde1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tk_ds[\"train\"],\n",
    "    eval_dataset=tk_ds[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5850ed-852f-4b51-9773-35c29e7a41e4",
   "metadata": {},
   "source": [
    "# In here i made a mistakes: the targets value was english too instead of turkish. thats why the loss values like this: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b2f6c7b4-45f5-4c4c-90e3-04aed4b40762",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['model.encoder.embed_tokens.weight', 'model.encoder.embed_positions.weight', 'model.decoder.embed_tokens.weight', 'model.decoder.embed_positions.weight', 'lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6474' max='6474' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6474/6474 3:08:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.002900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.002400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.001900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.001700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=6474, training_loss=0.0014031449419722205, metrics={'train_runtime': 11329.1515, 'train_samples_per_second': 36.568, 'train_steps_per_second': 0.571, 'total_flos': 5.735620995239117e+16, 'train_loss': 0.0014031449419722205, 'epoch': 3.0})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89a70d18-4593-4f54-9c4b-5f6505fcd27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgokhannergull\u001b[0m (\u001b[33mgokhannergull-student\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/gokhan/hugging_face/translate/wandb/run-20251012_175557-8r7ttdzt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gokhannergull-student/huggingface/runs/8r7ttdzt' target=\"_blank\">tough-dream-7</a></strong> to <a href='https://wandb.ai/gokhannergull-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gokhannergull-student/huggingface' target=\"_blank\">https://wandb.ai/gokhannergull-student/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gokhannergull-student/huggingface/runs/8r7ttdzt' target=\"_blank\">https://wandb.ai/gokhannergull-student/huggingface/runs/8r7ttdzt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4316' max='4316' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4316/4316 2:02:47, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.716600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.113600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.107300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.102200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.093700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.090600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.089400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.088900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gokhan/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/transformers/modeling_utils.py:4037: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[57059]], 'forced_eos_token_id': 43741}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4316, training_loss=0.28476363315529246, metrics={'train_runtime': 7372.4471, 'train_samples_per_second': 37.462, 'train_steps_per_second': 0.585, 'total_flos': 3.740743108657152e+16, 'train_loss': 0.28476363315529246, 'epoch': 2.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "472480f2-9a3f-4e43-bb51-8d9feddba6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bddc5778-f310-4e7d-a45b-1372113b88f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model_path = \"./kde4-en-to-tr_with-Helsinki\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(local_model_path)\n",
    "\n",
    "tokenizer_path = 'Helsinki-NLP/opus-mt-tc-big-en-tr'\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "75dd071f-209e-49c3-b396-264d8302daa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tüm dosyalar './-en-to-tr_with-Helsinki_ALL' klasörüne başarıyla kaydedildi!\n"
     ]
    }
   ],
   "source": [
    "save_directory = \"./-en-to-tr_with-Helsinki_ALL\"\n",
    "model.save_pretrained(save_directory)\n",
    "tokenizer.save_pretrained(save_directory)\n",
    "\n",
    "print(f\"Tüm dosyalar '{save_directory}' klasörüne başarıyla kaydedildi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c12e01e-9972-41b4-8555-f5c7f679c318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec6dcaa4de34aed8046ca9218acf6a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5136b4c01ce4bc0874f4c766b203fec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload: |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/gokhanErgul/kde4-en-to-tr_with-Helsinki/commit/7592bbe0805514df5bc4a56b6a2af66ae109395e', commit_message='Upload folder using huggingface_hub', commit_description='', oid='7592bbe0805514df5bc4a56b6a2af66ae109395e', pr_url=None, repo_url=RepoUrl('https://huggingface.co/gokhanErgul/kde4-en-to-tr_with-Helsinki', endpoint='https://huggingface.co', repo_type='model', repo_id='gokhanErgul/kde4-en-to-tr_with-Helsinki'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path=\"./-en-to-tr_with-Helsinki_ALL\", \n",
    "    repo_id=\"gokhanErgul/kde4-en-to-tr_with-Helsinki\",\n",
    "    repo_type=\"model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "321cc63b-c163-4a50-9609-2b2e3a879e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gokhan/miniconda3/envs/pytorch-gpu/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    }
   ],
   "source": [
    "model_path = \"gokhanErgul/kde4-en-to-tr_with-Helsinki\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5174f9e7-2167-4272-9e03-9cb6f94573f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_914/2180442542.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tk_ds[\"train\"],\n",
    "    eval_dataset=tk_ds[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a240793a-4d01-41eb-b4d3-aa14c83c605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generation_config.max_length = 128\n",
    "model.generation_config.num_beams = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64b6db3d-020e-4cc7-a5ea-327d78fec656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='959' max='959' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [959/959 12:32]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.0s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/gokhan/hugging_face/translate/wandb/run-20251013_153326-i326cru3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/gokhannergull-student/huggingface/runs/i326cru3' target=\"_blank\">dandy-pine-8</a></strong> to <a href='https://wandb.ai/gokhannergull-student/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/gokhannergull-student/huggingface' target=\"_blank\">https://wandb.ai/gokhannergull-student/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/gokhannergull-student/huggingface/runs/i326cru3' target=\"_blank\">https://wandb.ai/gokhannergull-student/huggingface/runs/i326cru3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation_results = trainer.evaluate(max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14ca96f2-c06d-4821-bffa-ab5039831e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 9.745146751403809,\n",
       " 'eval_model_preparation_time': 0.003,\n",
       " 'eval_bleu': 28.943267751793897,\n",
       " 'eval_runtime': 766.7728,\n",
       " 'eval_samples_per_second': 20.011,\n",
       " 'eval_steps_per_second': 1.251}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99e21f6-b130-4b61-ab72-9cc303df256c",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4dc2577-9345-41b3-9128-653099b190d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MarianMTModel(\n",
       "  (model): MarianModel(\n",
       "    (shared): Embedding(57060, 1024, padding_idx=57059)\n",
       "    (encoder): MarianEncoder(\n",
       "      (embed_tokens): Embedding(57060, 1024, padding_idx=57059)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(1024, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): MarianDecoder(\n",
       "      (embed_tokens): Embedding(57060, 1024, padding_idx=57059)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(1024, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=57060, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96f90877-ec75-42c1-be20-e1d3f02156ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kitap masanın üzerinde.'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_to_translate = \"The book is on the table.\"\n",
    "inputs = tokenizer(text_to_translate, return_tensors='pt')\n",
    "inputs = {k: v.to(device) for k,v in inputs.items()}\n",
    "output_tokens= model.generate(**inputs, max_length = 128,num_beams=4)\n",
    "output_to_text = tokenizer.decode(output_tokens[0],skip_special_tokens=True)\n",
    "output_to_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c9335a-ce5c-42d6-9202-620f6743d7d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch (GPU)",
   "language": "python",
   "name": "pytorch-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
